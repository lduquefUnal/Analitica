{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cc5830e",
   "metadata": {},
   "source": [
    "Utilizando el dataset \" Twitter Sentiment Analysis in Spanish Tweets\", deberÃ¡s\n",
    "implementar y comparar diferentes tÃ©cnicas de Inteligencia Artificial y Modelos de\n",
    "Lenguaje (LLM) para la clasificaciÃ³n de sentimientos en comentarios de usuarios.\n",
    "â€¢ Demostrar conocimientos prÃ¡cticos en tÃ©cnicas de IA/ML\n",
    "â€¢ Evaluar capacidad de prompt engineering con LLMs\n",
    "â€¢ Analizar crÃ­ticamente los resultados obtenidos\n",
    "â€¢ Muestra a utilizar: Los primeros 100 datos seleccionados aleatoriamente\n",
    "â€¢ Etiquetas esperadas: POSITIVO, NEGATIVO, NEUTRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06cbee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad8e859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@erreborda</td>\n",
       "      <td>termine bien abrumado despuÃ©s de hoy</td>\n",
       "      <td>Jan 6, 2024 Â· 2:53 AM UTC</td>\n",
       "      <td>overwhelmed</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@shpiderduck</td>\n",
       "      <td>me siento abrumado</td>\n",
       "      <td>Jan 6, 2024 Â· 2:35 AM UTC</td>\n",
       "      <td>overwhelmed</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Alex_R_art</td>\n",
       "      <td>Me siento un poco abrumado por la cantidad de ...</td>\n",
       "      <td>Jan 6, 2024 Â· 12:20 AM UTC</td>\n",
       "      <td>overwhelmed</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@anggelinaa97</td>\n",
       "      <td>Salvador la Ãºnica persona que no la ha abrumad...</td>\n",
       "      <td>Jan 5, 2024 Â· 10:38 PM UTC</td>\n",
       "      <td>overwhelmed</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@diegoreyesvqz</td>\n",
       "      <td>Denme un helado o algo que ando full abrumado.</td>\n",
       "      <td>Jan 5, 2024 Â· 8:38 PM UTC</td>\n",
       "      <td>overwhelmed</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user                                               text  \\\n",
       "0      @erreborda               termine bien abrumado despuÃ©s de hoy   \n",
       "1    @shpiderduck                                 me siento abrumado   \n",
       "2     @Alex_R_art  Me siento un poco abrumado por la cantidad de ...   \n",
       "3   @anggelinaa97  Salvador la Ãºnica persona que no la ha abrumad...   \n",
       "4  @diegoreyesvqz     Denme un helado o algo que ando full abrumado.   \n",
       "\n",
       "                         date      emotion sentiment  \n",
       "0   Jan 6, 2024 Â· 2:53 AM UTC  overwhelmed    scared  \n",
       "1   Jan 6, 2024 Â· 2:35 AM UTC  overwhelmed    scared  \n",
       "2  Jan 6, 2024 Â· 12:20 AM UTC  overwhelmed    scared  \n",
       "3  Jan 5, 2024 Â· 10:38 PM UTC  overwhelmed    scared  \n",
       "4   Jan 5, 2024 Â· 8:38 PM UTC  overwhelmed    scared  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sentiment_analysis_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fd8169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategorÃ­as en 'emotion': ['overwhelmed' 'embarrassed' 'jealous' 'irritated' 'frustrated' 'distant'\n",
      " 'stupid' 'isolated' 'sleepy' 'responsive' 'relaxed' 'loving' 'thankful'\n",
      " 'secure' 'confident' 'successful' 'surprised' 'playful' 'optimistic'\n",
      " 'daring']\n",
      "CategorÃ­as en 'sentiment': ['scared' 'mad' 'sad' 'peaceful' 'powerful' 'joyful']\n"
     ]
    }
   ],
   "source": [
    "print(\"CategorÃ­as en 'emotion':\", df['emotion'].unique())\n",
    "print(\"CategorÃ­as en 'sentiment':\", df['sentiment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e4baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text      emotion  \\\n",
      "2106                       El sorprendido fui yo jajaja    surprised   \n",
      "1391  En serio me gustarÃ­a tener un novio para ir a ...      relaxed   \n",
      "658             Ya estoy tan cansado tan harto tan todo   frustrated   \n",
      "1958  Fuero exclusivo o necesario: solo es competent...    confident   \n",
      "184                               Muy tÃ­mido el viernes  embarrassed   \n",
      "1520  pokemon concierge eh tao querido caloroso amav...       loving   \n",
      "1322  soy un chico tranquilito sosegado calmado adem...      relaxed   \n",
      "15             Desbordado de felicidad y de ansiedadðŸ¥¹ðŸ«¶ðŸ½  overwhelmed   \n",
      "2128  Y darÃ© en asombro Mi silencio Mueca de rostro ...    surprised   \n",
      "173   Me regalaron dos rosas bonitas ðŸ’• fue muy bonit...  embarrassed   \n",
      "\n",
      "     sentiment sentiment_label  \n",
      "2106  powerful        POSITIVO  \n",
      "1391  peaceful          NEUTRO  \n",
      "658        mad        NEGATIVO  \n",
      "1958  powerful        POSITIVO  \n",
      "184     scared        NEGATIVO  \n",
      "1520  peaceful        POSITIVO  \n",
      "1322  peaceful          NEUTRO  \n",
      "15      scared        NEGATIVO  \n",
      "2128  powerful        POSITIVO  \n",
      "173     scared        NEGATIVO  \n",
      "sentiment_label\n",
      "POSITIVO    1190\n",
      "NEGATIVO    1160\n",
      "NEUTRO       240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Diccionarios de mapeo\n",
    "emotion_map = {\n",
    "    'overwhelmed': 'NEGATIVO', 'embarrassed': 'NEGATIVO', 'jealous': 'NEGATIVO',\n",
    "    'irritated': 'NEGATIVO', 'frustrated': 'NEGATIVO', 'distant': 'NEGATIVO',\n",
    "    'stupid': 'NEGATIVO', 'isolated': 'NEGATIVO', 'sleepy': 'NEGATIVO',\n",
    "\n",
    "    'responsive': 'NEUTRO', 'relaxed': 'NEUTRO',\n",
    "\n",
    "    'loving': 'POSITIVO', 'thankful': 'POSITIVO', 'secure': 'POSITIVO',\n",
    "    'confident': 'POSITIVO', 'successful': 'POSITIVO', 'surprised': 'POSITIVO',\n",
    "    'playful': 'POSITIVO', 'optimistic': 'POSITIVO', 'daring': 'POSITIVO'\n",
    "}\n",
    "\n",
    "sentiment_map = {\n",
    "    'scared': 'NEGATIVO', 'mad': 'NEGATIVO', 'sad': 'NEGATIVO',\n",
    "    'peaceful': 'NEUTRO',\n",
    "    'powerful': 'POSITIVO', 'joyful': 'POSITIVO'\n",
    "}\n",
    "\n",
    "# Combinar ambos mapas para una sola columna final\n",
    "def combine_sentiment(row):\n",
    "    e = emotion_map.get(row['emotion'], 'NEUTRO')\n",
    "    s = sentiment_map.get(row['sentiment'], 'NEUTRO')\n",
    "    # Regla: si alguno es NEGATIVO => NEGATIVO; si alguno es POSITIVO => POSITIVO\n",
    "    if 'NEGATIVO' in (e, s):\n",
    "        return 'NEGATIVO'\n",
    "    elif 'POSITIVO' in (e, s):\n",
    "        return 'POSITIVO'\n",
    "    else:\n",
    "        return 'NEUTRO'\n",
    "\n",
    "df['sentiment_label'] = df.apply(combine_sentiment, axis=1)\n",
    "\n",
    "# Verifica el resultado\n",
    "print(df[['text', 'emotion', 'sentiment', 'sentiment_label']].sample(10))\n",
    "print(df['sentiment_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aadfb612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_label\n",
      "NEGATIVO    48\n",
      "POSITIVO    33\n",
      "NEUTRO      19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Usando CountVectorizer ---\n",
      "\n",
      "Modelo: Logistic Regression\n",
      "Accuracy: 0.7857\n",
      "F1-score (macro): 0.6607\n",
      "Matriz de confusiÃ³n:\n",
      "[[199  33   6]\n",
      " [ 33 196   3]\n",
      " [ 22  14  12]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.8066    0.8448    0.8253       232\n",
      "      NEUTRO     0.5714    0.2500    0.3478        48\n",
      "    POSITIVO     0.7835    0.8361    0.8089       238\n",
      "\n",
      "    accuracy                         0.7857       518\n",
      "   macro avg     0.7205    0.6437    0.6607       518\n",
      "weighted avg     0.7742    0.7857    0.7735       518\n",
      "\n",
      "\n",
      "Modelo: Naive Bayes\n",
      "Accuracy: 0.7645\n",
      "F1-score (macro): 0.5486\n",
      "Matriz de confusiÃ³n:\n",
      "[[205  29   4]\n",
      " [ 41 190   1]\n",
      " [ 24  23   1]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.7851    0.8190    0.8017       232\n",
      "      NEUTRO     0.1667    0.0208    0.0370        48\n",
      "    POSITIVO     0.7593    0.8613    0.8071       238\n",
      "\n",
      "    accuracy                         0.7645       518\n",
      "   macro avg     0.5703    0.5670    0.5486       518\n",
      "weighted avg     0.7159    0.7645    0.7333       518\n",
      "\n",
      "\n",
      "Modelo: Linear SVM\n",
      "Accuracy: 0.7857\n",
      "F1-score (macro): 0.6607\n",
      "Matriz de confusiÃ³n:\n",
      "[[199  33   6]\n",
      " [ 33 196   3]\n",
      " [ 22  14  12]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.8066    0.8448    0.8253       232\n",
      "      NEUTRO     0.5714    0.2500    0.3478        48\n",
      "    POSITIVO     0.7835    0.8361    0.8089       238\n",
      "\n",
      "    accuracy                         0.7857       518\n",
      "   macro avg     0.7205    0.6437    0.6607       518\n",
      "weighted avg     0.7742    0.7857    0.7735       518\n",
      "\n",
      "\n",
      "Modelo: Naive Bayes\n",
      "Accuracy: 0.7645\n",
      "F1-score (macro): 0.5486\n",
      "Matriz de confusiÃ³n:\n",
      "[[205  29   4]\n",
      " [ 41 190   1]\n",
      " [ 24  23   1]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.7851    0.8190    0.8017       232\n",
      "      NEUTRO     0.1667    0.0208    0.0370        48\n",
      "    POSITIVO     0.7593    0.8613    0.8071       238\n",
      "\n",
      "    accuracy                         0.7645       518\n",
      "   macro avg     0.5703    0.5670    0.5486       518\n",
      "weighted avg     0.7159    0.7645    0.7333       518\n",
      "\n",
      "\n",
      "Modelo: Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luisduquefranco/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8224\n",
      "F1-score (macro): 0.7713\n",
      "Matriz de confusiÃ³n:\n",
      "[[205  26   7]\n",
      " [ 35 194   3]\n",
      " [ 13   8  27]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.8509    0.8362    0.8435       232\n",
      "      NEUTRO     0.7297    0.5625    0.6353        48\n",
      "    POSITIVO     0.8103    0.8613    0.8350       238\n",
      "\n",
      "    accuracy                         0.8224       518\n",
      "   macro avg     0.7970    0.7534    0.7713       518\n",
      "weighted avg     0.8210    0.8224    0.8203       518\n",
      "\n",
      "\n",
      "--- Usando TfidfVectorizer ---\n",
      "\n",
      "Modelo: Logistic Regression\n",
      "Accuracy: 0.7625\n",
      "F1-score (macro): 0.5580\n",
      "Matriz de confusiÃ³n:\n",
      "[[208  29   1]\n",
      " [ 47 185   0]\n",
      " [ 26  20   2]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.7906    0.7974    0.7940       232\n",
      "      NEUTRO     0.6667    0.0417    0.0784        48\n",
      "    POSITIVO     0.7402    0.8739    0.8015       238\n",
      "\n",
      "    accuracy                         0.7625       518\n",
      "   macro avg     0.7325    0.5710    0.5580       518\n",
      "weighted avg     0.7560    0.7625    0.7312       518\n",
      "\n",
      "\n",
      "Modelo: Naive Bayes\n",
      "Accuracy: 0.7761\n",
      "F1-score (macro): 0.5424\n",
      "Matriz de confusiÃ³n:\n",
      "[[213  25   0]\n",
      " [ 43 189   0]\n",
      " [ 28  20   0]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.8077    0.8147    0.8112       232\n",
      "      NEUTRO     0.0000    0.0000    0.0000        48\n",
      "    POSITIVO     0.7500    0.8950    0.8161       238\n",
      "\n",
      "    accuracy                         0.7761       518\n",
      "   macro avg     0.5192    0.5699    0.5424       518\n",
      "weighted avg     0.7063    0.7761    0.7383       518\n",
      "\n",
      "\n",
      "Modelo: Linear SVM\n",
      "Accuracy: 0.8089\n",
      "F1-score (macro): 0.7122\n",
      "Matriz de confusiÃ³n:\n",
      "[[208  23   7]\n",
      " [ 34 193   5]\n",
      " [ 21   9  18]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.8578    0.8319    0.8446       232\n",
      "      NEUTRO     0.6000    0.3750    0.4615        48\n",
      "    POSITIVO     0.7909    0.8739    0.8303       238\n",
      "\n",
      "    accuracy                         0.8089       518\n",
      "   macro avg     0.7496    0.6936    0.7122       518\n",
      "weighted avg     0.8032    0.8089    0.8026       518\n",
      "\n",
      "Accuracy: 0.7625\n",
      "F1-score (macro): 0.5580\n",
      "Matriz de confusiÃ³n:\n",
      "[[208  29   1]\n",
      " [ 47 185   0]\n",
      " [ 26  20   2]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.7906    0.7974    0.7940       232\n",
      "      NEUTRO     0.6667    0.0417    0.0784        48\n",
      "    POSITIVO     0.7402    0.8739    0.8015       238\n",
      "\n",
      "    accuracy                         0.7625       518\n",
      "   macro avg     0.7325    0.5710    0.5580       518\n",
      "weighted avg     0.7560    0.7625    0.7312       518\n",
      "\n",
      "\n",
      "Modelo: Naive Bayes\n",
      "Accuracy: 0.7761\n",
      "F1-score (macro): 0.5424\n",
      "Matriz de confusiÃ³n:\n",
      "[[213  25   0]\n",
      " [ 43 189   0]\n",
      " [ 28  20   0]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.8077    0.8147    0.8112       232\n",
      "      NEUTRO     0.0000    0.0000    0.0000        48\n",
      "    POSITIVO     0.7500    0.8950    0.8161       238\n",
      "\n",
      "    accuracy                         0.7761       518\n",
      "   macro avg     0.5192    0.5699    0.5424       518\n",
      "weighted avg     0.7063    0.7761    0.7383       518\n",
      "\n",
      "\n",
      "Modelo: Linear SVM\n",
      "Accuracy: 0.8089\n",
      "F1-score (macro): 0.7122\n",
      "Matriz de confusiÃ³n:\n",
      "[[208  23   7]\n",
      " [ 34 193   5]\n",
      " [ 21   9  18]]\n",
      "Reporte de clasificaciÃ³n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVO     0.8578    0.8319    0.8446       232\n",
      "      NEUTRO     0.6000    0.3750    0.4615        48\n",
      "    POSITIVO     0.7909    0.8739    0.8303       238\n",
      "\n",
      "    accuracy                         0.8089       518\n",
      "   macro avg     0.7496    0.6936    0.7122       518\n",
      "weighted avg     0.8032    0.8089    0.8026       518\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luisduquefranco/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/luisduquefranco/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/luisduquefranco/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# selecciono 100 al azar para acelerar pruebas\n",
    "\n",
    "df_sample = df.sample(n=100, random_state=42).reset_index(drop=True)\n",
    "print(df_sample['sentiment_label'].value_counts())\n",
    "\n",
    "\n",
    "# Selecciona el texto y la etiqueta\n",
    "X = df['text']\n",
    "y = df['sentiment_label']\n",
    "\n",
    "# Divide en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Prueba ambas vectorizaciones\n",
    "vectorizers = {\n",
    "    \"CountVectorizer\": CountVectorizer(),\n",
    "    \"TfidfVectorizer\": TfidfVectorizer()\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Linear SVM\": LinearSVC()\n",
    "}\n",
    "\n",
    "for vec_name, vectorizer in vectorizers.items():\n",
    "    print(f\"\\n--- Usando {vec_name} ---\")\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nModelo: {model_name}\")\n",
    "        model.fit(X_train_vec, y_train)\n",
    "        y_pred = model.predict(X_test_vec)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=['POSITIVO', 'NEGATIVO', 'NEUTRO'])\n",
    "        \n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(f\"F1-score (macro): {f1:.4f}\")\n",
    "        print(\"Matriz de confusiÃ³n:\")\n",
    "        print(cm)\n",
    "        print(\"Reporte de clasificaciÃ³n:\")\n",
    "        print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fccf7",
   "metadata": {},
   "source": [
    "## InterpretaciÃ³n de resultados y modelo recomendado\n",
    "Se compararon tres modelos de clasificaciÃ³n de sentimientos (Logistic Regression, Naive Bayes y Linear SVM) usando dos tÃ©cnicas de vectorizaciÃ³n de texto (CountVectorizer y TfidfVectorizer).\n",
    "- **CountVectorizer**: Linear SVM obtuvo la mejor precisiÃ³n (Accuracy: 0.82, F1 macro: 0.77), mostrando buen desempeÃ±o en las clases POSITIVO y NEGATIVO, aunque la clase NEUTRO fue la mÃ¡s difÃ­cil de predecir (menor recall y f1-score).\n",
    "- **TfidfVectorizer**: Linear SVM tambiÃ©n fue el mejor (Accuracy: 0.81, F1 macro: 0.71), pero la clase NEUTRO sigue siendo la menos representada correctamente.\n",
    "En general, **Linear SVM con CountVectorizer** fue el modelo mÃ¡s robusto, logrando el mejor balance entre precisiÃ³n y F1-score macro. Sin embargo, todos los modelos presentan dificultades para clasificar correctamente la clase NEUTRO, posiblemente por desbalance de clases o menor informaciÃ³n en los textos asociados.\n",
    "**ConclusiÃ³n:** El modelo recomendado es **Linear SVM con CountVectorizer**, ya que ofrece el mejor desempeÃ±o global en este problema de clasificaciÃ³n de sentimientos en tweets en espaÃ±ol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47ab245",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/openai/_base_client.py:1027\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     34\u001b[39m df_test = df.loc[X_test.index].copy()\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# âš ï¸ Si el dataset es grande, prueba con un subconjunto\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# df_test = df_test.sample(20, random_state=42)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m df_test[\u001b[33m\"\u001b[39m\u001b[33mpred_llm\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_llm_prediction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m time.sleep(\u001b[32m1\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# ðŸ”¹ EvaluaciÃ³n de desempeÃ±o\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/pandas/core/series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mget_llm_prediction\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     10\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33mClasifica el siguiente tweet en una de las categorÃ­as: POSITIVO, NEGATIVO o NEUTRO.\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33mTweet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33mResponde solo con una palabra: POSITIVO, NEGATIVO o NEUTRO.\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# o \"gpt-3.5-turbo\"\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     label = response.choices[\u001b[32m0\u001b[39m].message.content.strip().upper()\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Aseguramos que la salida sea vÃ¡lida\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/openai/_base_client.py:1033\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1032\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Entrevistas/Analitica/Analitica/analitica/lib64/python3.13/site-packages/openai/_base_client.py:1073\u001b[39m, in \u001b[36mSyncAPIClient._sleep_for_retry\u001b[39m\u001b[34m(self, retries_taken, max_retries, options, response)\u001b[39m\n\u001b[32m   1070\u001b[39m timeout = \u001b[38;5;28mself\u001b[39m._calculate_retry_timeout(remaining_retries, options, response.headers \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1071\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# ðŸ”¹ Predicciones usando un LLM (OpenAI GPT-4)\n",
    "# -------------------------------------------------------\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "def get_llm_prediction(text):\n",
    "    prompt = f\"\"\"\n",
    "    Clasifica el siguiente tweet en una de las categorÃ­as: POSITIVO, NEGATIVO o NEUTRO.\n",
    "    Tweet: {text}\n",
    "    Responde solo con una palabra: POSITIVO, NEGATIVO o NEUTRO.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # o \"gpt-3.5-turbo\"\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=5,\n",
    "            temperature=0\n",
    "        )\n",
    "        label = response.choices[0].message.content.strip().upper()\n",
    "        # Aseguramos que la salida sea vÃ¡lida\n",
    "        if label not in [\"POSITIVO\", \"NEGATIVO\", \"NEUTRO\"]:\n",
    "            label = \"NEUTRO\"\n",
    "        return label\n",
    "    except Exception as e:\n",
    "        print(f\"Error con el texto: {text[:50]} -> {e}\")\n",
    "        return \"NEUTRO\"\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ðŸ”¹ Aplica el modelo LLM sobre los datos de test\n",
    "# -------------------------------------------------------\n",
    "df_test = df.loc[X_test.index].copy()\n",
    "\n",
    "# âš ï¸ Si el dataset es grande, prueba con un subconjunto\n",
    "# df_test = df_test.sample(20, random_state=42)\n",
    "\n",
    "df_test[\"pred_llm\"] = df_test[\"text\"].apply(get_llm_prediction)\n",
    "time.sleep(1)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ðŸ”¹ EvaluaciÃ³n de desempeÃ±o\n",
    "# -------------------------------------------------------\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "acc_llm = accuracy_score(df_test[\"sentiment_label\"], df_test[\"pred_llm\"])\n",
    "f1_llm = f1_score(df_test[\"sentiment_label\"], df_test[\"pred_llm\"], average=\"macro\")\n",
    "cm_llm = confusion_matrix(df_test[\"sentiment_label\"], df_test[\"pred_llm\"], labels=[\"POSITIVO\", \"NEGATIVO\", \"NEUTRO\"])\n",
    "\n",
    "print(f\"âœ… Accuracy LLM: {acc_llm:.4f}\")\n",
    "print(f\"âœ… F1-score (macro) LLM: {f1_llm:.4f}\")\n",
    "print(\"\\nMatriz de confusiÃ³n LLM:\")\n",
    "print(cm_llm)\n",
    "print(\"\\nReporte de clasificaciÃ³n LLM:\")\n",
    "print(classification_report(df_test[\"sentiment_label\"], df_test[\"pred_llm\"], digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554c5cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# ðŸ”¹ Predicciones con modelo de HuggingFace (BETO)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Carga el pipeline de anÃ¡lisis de sentimiento\u001b[39;00m\n\u001b[32m      7\u001b[39m sentiment_pipeline = pipeline(\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msentiment-analysis\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mpysentimiento/bert-base-spanish-uncased\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# ðŸ”¹ Predicciones con modelo de HuggingFace (BETO)\n",
    "# -------------------------------------------------------\n",
    "from transformers import pipeline\n",
    "\n",
    "# Carga el pipeline de anÃ¡lisis de sentimiento\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"pysentimiento/bert-base-spanish-uncased\"\n",
    ")\n",
    "\n",
    "def get_llm_prediction(text):\n",
    "    result = sentiment_pipeline(text[:512])[0]\n",
    "    label = result[\"label\"].upper()\n",
    "    if \"POS\" in label:\n",
    "        return \"POSITIVO\"\n",
    "    elif \"NEG\" in label:\n",
    "        return \"NEGATIVO\"\n",
    "    else:\n",
    "        return \"NEUTRO\"\n",
    "\n",
    "# Aplicar a los datos de test\n",
    "df_test = df.loc[X_test.index].copy()\n",
    "df_test[\"pred_llm\"] = df_test[\"text\"].apply(get_llm_prediction)\n",
    "\n",
    "# Evaluar desempeÃ±o\n",
    "acc_llm = accuracy_score(df_test[\"sentiment_label\"], df_test[\"pred_llm\"])\n",
    "f1_llm = f1_score(df_test[\"sentiment_label\"], df_test[\"pred_llm\"], average=\"macro\")\n",
    "cm_llm = confusion_matrix(df_test[\"sentiment_label\"], df_test[\"pred_llm\"], labels=[\"POSITIVO\", \"NEGATIVO\", \"NEUTRO\"])\n",
    "\n",
    "print(f\"âœ… Accuracy LLM: {acc_llm:.4f}\")\n",
    "print(f\"âœ… F1-score (macro) LLM: {f1_llm:.4f}\")\n",
    "print(\"\\nMatriz de confusiÃ³n LLM:\")\n",
    "print(cm_llm)\n",
    "print(\"\\nReporte de clasificaciÃ³n LLM:\")\n",
    "print(classification_report(df_test[\"sentiment_label\"], df_test[\"pred_llm\"], digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analitica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
